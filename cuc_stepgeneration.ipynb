{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passsing only existing steps in prompt to the model\n",
    "# Working\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import openai\n",
    "import openai\n",
    "import re\n",
    "\n",
    "class ScenarioGenerator:\n",
    "    def __init__(self, azure_api_key, azure_endpoint, deployment_name):\n",
    "        self.azure_api_key = azure_api_key\n",
    "        self.azure_endpoint = azure_endpoint\n",
    "        self.deployment_name = deployment_name\n",
    "        \n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_base = azure_endpoint\n",
    "        openai.api_version = \"2024-02-15-preview\"\n",
    "        openai.api_key = azure_api_key\n",
    "        \n",
    "        self.llm = AzureChatOpenAI(\n",
    "            openai_api_key=azure_api_key,\n",
    "            openai_api_base=azure_endpoint,\n",
    "            openai_api_version=\"2024-02-15-preview\",\n",
    "            deployment_name=deployment_name,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            openai_api_key=azure_api_key,\n",
    "            openai_api_base=azure_endpoint,\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version=\"2024-02-15-preview\",\n",
    "            deployment=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        \n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "    \n",
    "    def generate_scenario(self, scenario_description, existing_steps_file):\n",
    "        with open(existing_steps_file, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "            \n",
    "        texts = self.text_splitter.split_text(content)\n",
    "        vectorstore = FAISS.from_texts(texts, self.embeddings)\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are an AI assistant that provides accurate and concise responses.\"),\n",
    "            (\"human\", \"\"\"\n",
    "            here is my existing scenario cucumber steps, create another cucumber scenario reusing the steps which I already have, feel free to modify any variable in the step if needed. For any step, if its not defined in the provided scenario cucumber steps, create a new step and add a comment tag \"NEW STEP\" right before that line.\n",
    "\n",
    "            Create new scenario for:\n",
    "            {question} \n",
    "\n",
    "            existing scenario cucumber steps:\n",
    "            {context}\n",
    "            \"\"\")\n",
    "        ])\n",
    "        \n",
    "        scenario_chain = create_stuff_documents_chain(\n",
    "            self.llm,\n",
    "            prompt,\n",
    "            document_variable_name=\"context\"\n",
    "        )\n",
    "        \n",
    "        docs = vectorstore.similarity_search(scenario_description, k=5)\n",
    "        response = scenario_chain.invoke({\n",
    "            \"question\": scenario_description,\n",
    "            \"context\": docs\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "\n",
    "class StepDefinitionGenerator:\n",
    "    def __init__(self, azure_api_key, azure_endpoint, deployment_name):\n",
    "        self.azure_api_key = azure_api_key\n",
    "        self.azure_endpoint = azure_endpoint\n",
    "        self.deployment_name = deployment_name\n",
    "        \n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_base = azure_endpoint\n",
    "        openai.api_version = \"2024-02-15-preview\"\n",
    "        openai.api_key = azure_api_key\n",
    "    \n",
    "    def extract_new_steps(self, generated_scenario):\n",
    "        new_steps = []\n",
    "\n",
    "        # with open(\"all_steps.txt\", 'r', encoding='utf-8') as file:\n",
    "        #     content = file.read().split('\\n')\n",
    "        #     content = [line.strip() for line in content if line.strip()]\n",
    "\n",
    "        # for line in generated_scenario.split('\\n'):\n",
    "        #     pattern = r'^(Given|When|Then|And|But)\\s+'\n",
    "        #     if re.match(pattern, line.strip()):\n",
    "        #         line = re.sub(pattern, '', line.strip())\n",
    "        #         if (line not in content):\n",
    "        #             step = line.strip()\n",
    "        #             new_steps.append(step)\n",
    "\n",
    "        save_step = False\n",
    "        for line in generated_scenario.split('\\n'):\n",
    "            if \"NEW STEP\" in line:\n",
    "                save_step = True\n",
    "                continue\n",
    "            if save_step:\n",
    "                new_steps.append(line)\n",
    "                save_step = False\n",
    "        exit\n",
    "        return new_steps\n",
    "    \n",
    "    def generate_step_definition(self, step, existing_step_file):\n",
    "        \n",
    "        step_pattern = re.sub(r'^(Given|When|Then|And|But)\\s+', '', step)\n",
    "        step_pattern = re.sub(r'\"([^\"]*)\"', '(.*)', step_pattern)\n",
    "        step_pattern = re.sub(r'<([^>]*)>', '(.*)', step_pattern)\n",
    "        \n",
    "        try:\n",
    "            response = openai.ChatCompletion.create(\n",
    "                engine=self.deployment_name,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": \"\"\"You are an AI assistant that provides accurate and concise responses.\n",
    "                    Generate Java step definitions for the provided Cucumber steps.\n",
    "                    \n",
    "                    Follow these rules:\n",
    "                    1. Use Java syntax with Cucumber's step definition patterns\n",
    "                    2. Include appropriate assertions and verifications\n",
    "                    3. Handle any parameters or variables in the step\n",
    "                    4. Include comments explaining complex logic\"\"\"},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                    All Scenario Steps:\n",
    "                    {existing_step_file}\n",
    "                    \n",
    "                    Generate step definition for this step:\n",
    "                    {step_pattern}\n",
    "                    \"\"\"}\n",
    "                ]\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"Error generating step definition: {str(e)}\"\n",
    "\n",
    "def main():\n",
    "    scenario_gen = ScenarioGenerator(\n",
    "        azure_api_key=\"<API_KEY>\",\n",
    "        azure_endpoint=\"https://cuc2024winterg1743692136.openai.azure.com/\",\n",
    "        deployment_name=\"gpt-4\"\n",
    "    )\n",
    "    \n",
    "    step_def_gen = StepDefinitionGenerator(\n",
    "        azure_api_key=\"<API_KEY>\",\n",
    "        azure_endpoint=\"https://cuc2024winterg1743692136.openai.azure.com/\",\n",
    "        deployment_name=\"FineTunedCucumberModel\"\n",
    "    )\n",
    "    \n",
    "    scenario = \"\"\"\n",
    "    Create a preset and use it in creating a new campaign and associate multilingual setting to campaign and publish the campaign\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_scenario = scenario_gen.generate_scenario(\n",
    "        scenario,\n",
    "        \"all_steps.txt\"\n",
    "    )\n",
    "    print(generated_scenario)\n",
    "    \n",
    "    new_steps = step_def_gen.extract_new_steps(generated_scenario)\n",
    "    \n",
    "    for step in new_steps:\n",
    "        step_def = step_def_gen.generate_step_definition(\n",
    "            step, generated_scenario\n",
    "        )\n",
    "        print(f\"\\nStep: {step}\")\n",
    "        print(\"Step Definition:\")\n",
    "        print(step_def)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passsing existing steps as well as existing complete sceanrio context in prompt to the model\n",
    "# Not Complete right now, was not able to test because of exceeded rate limit\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import openai\n",
    "import time\n",
    "\n",
    "class CucumberStepGenerator:\n",
    "    def __init__(self, azure_api_key, azure_endpoint, deployment_name):\n",
    "        self.azure_api_key = azure_api_key\n",
    "        self.azure_endpoint = azure_endpoint\n",
    "        self.deployment_name = deployment_name\n",
    "        \n",
    "        openai.api_type = \"azure\"\n",
    "        openai.api_base = azure_endpoint\n",
    "        openai.api_version = \"2024-02-15-preview\"\n",
    "        openai.api_key = azure_api_key\n",
    "        \n",
    "        self.llm = AzureChatOpenAI(\n",
    "            openai_api_key=azure_api_key,\n",
    "            openai_api_base=azure_endpoint,\n",
    "            openai_api_version=\"2024-02-15-preview\",\n",
    "            deployment_name=deployment_name,\n",
    "            temperature=0.3\n",
    "        )\n",
    "        \n",
    "        self.embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-ada-002\",\n",
    "            openai_api_key=azure_api_key,\n",
    "            openai_api_base=azure_endpoint,\n",
    "            openai_api_type=\"azure\",\n",
    "            openai_api_version=\"2024-02-15-preview\",\n",
    "            deployment=\"text-embedding-ada-002\"\n",
    "        )\n",
    "        \n",
    "        self.steps_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            length_function=len\n",
    "        )\n",
    "\n",
    "        self.scenario_splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n##\"],\n",
    "            chunk_size=2000,\n",
    "            chunk_overlap=0,\n",
    "            length_function=len\n",
    "        )\n",
    "        \n",
    "    def load_contexts(self, steps_file, scenarios_file):\n",
    "        \"\"\"Load and process both steps and scenarios files separately\"\"\"\n",
    "\n",
    "        with open(steps_file, 'r', encoding='utf-8') as file:\n",
    "            steps_content = file.read()\n",
    "        step_texts = self.steps_splitter.split_text(steps_content)\n",
    "\n",
    "        self.steps_vectorstore = FAISS.from_texts(step_texts, self.embeddings)\n",
    "        \n",
    "        with open(scenarios_file, 'r', encoding='utf-8') as file:\n",
    "            scenarios_content = file.read()\n",
    "        scenario_texts = self.scenario_splitter.split_text(scenarios_content)\n",
    "\n",
    "        self.scenarios_vectorstore = FAISS.from_texts(scenario_texts, self.embeddings)\n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"You are an AI assistant that provides accurate and concise responses.\"\"\"),\n",
    "            (\"human\", \"\"\"\n",
    "            I will provide you with two types of context:\n",
    "            1. Individual cucumber steps that can be reused\n",
    "            2. Complete existing scenarios for reference\n",
    "            \n",
    "            Create a new scenario reusing existing steps where possible.\n",
    "            For any step that doesn't exist in the provided steps, create a new step \n",
    "            and mark it with '#completely new step'.\n",
    "\n",
    "            Create new scenario for:\n",
    "            {question}\n",
    "\n",
    "            Available individual steps for reuse:\n",
    "            {steps_context}\n",
    "\n",
    "            Example existing scenarios for reference:\n",
    "            {scenarios_context}\n",
    "\n",
    "            Make sure to:\n",
    "            1. Follow the same pattern as existing scenarios\n",
    "            2. Reuse existing steps where possible\n",
    "            3. Only mark truly new steps with #completely new step\n",
    "            4. Maintain the correct Given/When/Then/And order\n",
    "            \"\"\")\n",
    "        ])\n",
    "\n",
    "        \n",
    "        self.qa_chain = create_stuff_documents_chain(\n",
    "            self.llm,\n",
    "            prompt,\n",
    "            document_variable_name=\"context\"\n",
    "        )\n",
    "        \n",
    "    def generate_steps(self, scenario_description):\n",
    "        \"\"\"Generate Cucumber steps for a new scenario\"\"\"\n",
    "\n",
    "        relevant_steps = self.steps_vectorstore.similarity_search(scenario_description, k=3)\n",
    "        relevant_scenarios = self.scenarios_vectorstore.similarity_search(scenario_description, k=2)\n",
    "        \n",
    "        steps_text = \"\\n\".join(doc.page_content for doc in relevant_steps)\n",
    "\n",
    "        scenarios_text = \"\\n\".join(doc.page_content for doc in relevant_scenarios)\n",
    "\n",
    "        response = self.qa_chain.invoke({\n",
    "            \"question\": scenario_description,\n",
    "            \"steps_context\": steps_text,\n",
    "            \"scenarios_context\": scenarios_text\n",
    "        })\n",
    "        \n",
    "        return response\n",
    "\n",
    "def main():\n",
    "    generator = CucumberStepGenerator(\n",
    "        azure_api_key=\"<API_KEY>\",\n",
    "        azure_endpoint=\"https://cuc2024winterg1743692136.openai.azure.com/\",\n",
    "        deployment_name=\"gpt-4\"\n",
    "    )\n",
    "    \n",
    "    generator.load_contexts(\"all_steps.txt\", \"all_scenarios.txt\")\n",
    "    \n",
    "    scenario = \"\"\"\n",
    "    Create a campaign using email channel and associate multilingual setting to it and publish the campaign\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_steps = generator.generate_steps(scenario)\n",
    "    print(\"\\nGenerated Steps:\")\n",
    "    print(generated_steps)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
